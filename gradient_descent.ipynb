{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a5719d4-4b5d-46ce-9202-73419e920948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55135ab7-2ed9-40b2-8b05-8b14a39628e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100, n_features=1, n_informative=1, n_redundant=0, n_clusters_per_class=1, random_state=42)\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c79a3f82-2523-4bf1-a94c-9e800a0842a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a599ba5f-337b-46a6-a4f6-69224f9c53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, y_hat):\n",
    "    m = len(y)\n",
    "    loss = -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e23110c0-29a4-4c5f-8f25-2f8c3be341b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, learning_rate=0.01, iterations=10000):\n",
    "    m, n = X.shape\n",
    "    w = np.random.rand()\n",
    "    b = np.random.rand()\n",
    "\n",
    "    for i in range(iterations):\n",
    "        z = np.dot(X, w) + b\n",
    "        y_hat = sigmoid(z)\n",
    "        \n",
    "        dw = (1/m) * np.dot(X.T, (y_hat - y))\n",
    "        db = (1/m) * np.sum(y_hat - y)\n",
    "        \n",
    "        w -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "\n",
    "        loss = compute_loss(y, y_hat)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}: Loss = {loss:.4f}\")\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43a67d7c-1930-48bd-9be9-b80e977e01b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 0.3878\n",
      "Iteration 100: Loss = 0.3224\n",
      "Iteration 200: Loss = 0.2778\n",
      "Iteration 300: Loss = 0.2458\n",
      "Iteration 400: Loss = 0.2219\n",
      "Iteration 500: Loss = 0.2035\n",
      "Iteration 600: Loss = 0.1889\n",
      "Iteration 700: Loss = 0.1770\n",
      "Iteration 800: Loss = 0.1672\n",
      "Iteration 900: Loss = 0.1589\n",
      "Iteration 1000: Loss = 0.1519\n",
      "Iteration 1100: Loss = 0.1458\n",
      "Iteration 1200: Loss = 0.1405\n",
      "Iteration 1300: Loss = 0.1359\n",
      "Iteration 1400: Loss = 0.1318\n",
      "Iteration 1500: Loss = 0.1282\n",
      "Iteration 1600: Loss = 0.1249\n",
      "Iteration 1700: Loss = 0.1220\n",
      "Iteration 1800: Loss = 0.1193\n",
      "Iteration 1900: Loss = 0.1169\n",
      "Iteration 2000: Loss = 0.1146\n",
      "Iteration 2100: Loss = 0.1126\n",
      "Iteration 2200: Loss = 0.1107\n",
      "Iteration 2300: Loss = 0.1090\n",
      "Iteration 2400: Loss = 0.1074\n",
      "Iteration 2500: Loss = 0.1060\n",
      "Iteration 2600: Loss = 0.1046\n",
      "Iteration 2700: Loss = 0.1033\n",
      "Iteration 2800: Loss = 0.1021\n",
      "Iteration 2900: Loss = 0.1010\n",
      "Iteration 3000: Loss = 0.1000\n",
      "Iteration 3100: Loss = 0.0990\n",
      "Iteration 3200: Loss = 0.0980\n",
      "Iteration 3300: Loss = 0.0972\n",
      "Iteration 3400: Loss = 0.0964\n",
      "Iteration 3500: Loss = 0.0956\n",
      "Iteration 3600: Loss = 0.0948\n",
      "Iteration 3700: Loss = 0.0942\n",
      "Iteration 3800: Loss = 0.0935\n",
      "Iteration 3900: Loss = 0.0929\n",
      "Iteration 4000: Loss = 0.0923\n",
      "Iteration 4100: Loss = 0.0917\n",
      "Iteration 4200: Loss = 0.0912\n",
      "Iteration 4300: Loss = 0.0907\n",
      "Iteration 4400: Loss = 0.0902\n",
      "Iteration 4500: Loss = 0.0897\n",
      "Iteration 4600: Loss = 0.0893\n",
      "Iteration 4700: Loss = 0.0888\n",
      "Iteration 4800: Loss = 0.0884\n",
      "Iteration 4900: Loss = 0.0880\n",
      "Iteration 5000: Loss = 0.0877\n",
      "Iteration 5100: Loss = 0.0873\n",
      "Iteration 5200: Loss = 0.0870\n",
      "Iteration 5300: Loss = 0.0866\n",
      "Iteration 5400: Loss = 0.0863\n",
      "Iteration 5500: Loss = 0.0860\n",
      "Iteration 5600: Loss = 0.0857\n",
      "Iteration 5700: Loss = 0.0854\n",
      "Iteration 5800: Loss = 0.0852\n",
      "Iteration 5900: Loss = 0.0849\n",
      "Iteration 6000: Loss = 0.0847\n",
      "Iteration 6100: Loss = 0.0844\n",
      "Iteration 6200: Loss = 0.0842\n",
      "Iteration 6300: Loss = 0.0840\n",
      "Iteration 6400: Loss = 0.0837\n",
      "Iteration 6500: Loss = 0.0835\n",
      "Iteration 6600: Loss = 0.0833\n",
      "Iteration 6700: Loss = 0.0831\n",
      "Iteration 6800: Loss = 0.0829\n",
      "Iteration 6900: Loss = 0.0828\n",
      "Iteration 7000: Loss = 0.0826\n",
      "Iteration 7100: Loss = 0.0824\n",
      "Iteration 7200: Loss = 0.0822\n",
      "Iteration 7300: Loss = 0.0821\n",
      "Iteration 7400: Loss = 0.0819\n",
      "Iteration 7500: Loss = 0.0818\n",
      "Iteration 7600: Loss = 0.0816\n",
      "Iteration 7700: Loss = 0.0815\n",
      "Iteration 7800: Loss = 0.0814\n",
      "Iteration 7900: Loss = 0.0812\n",
      "Iteration 8000: Loss = 0.0811\n",
      "Iteration 8100: Loss = 0.0810\n",
      "Iteration 8200: Loss = 0.0808\n",
      "Iteration 8300: Loss = 0.0807\n",
      "Iteration 8400: Loss = 0.0806\n",
      "Iteration 8500: Loss = 0.0805\n",
      "Iteration 8600: Loss = 0.0804\n",
      "Iteration 8700: Loss = 0.0803\n",
      "Iteration 8800: Loss = 0.0802\n",
      "Iteration 8900: Loss = 0.0801\n",
      "Iteration 9000: Loss = 0.0800\n",
      "Iteration 9100: Loss = 0.0799\n",
      "Iteration 9200: Loss = 0.0798\n",
      "Iteration 9300: Loss = 0.0797\n",
      "Iteration 9400: Loss = 0.0796\n",
      "Iteration 9500: Loss = 0.0795\n",
      "Iteration 9600: Loss = 0.0795\n",
      "Iteration 9700: Loss = 0.0794\n",
      "Iteration 9800: Loss = 0.0793\n",
      "Iteration 9900: Loss = 0.0792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[4.39200744]]), 0.21795221017383062)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f0958-afea-4052-a8f4-8cef26e1e05b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
